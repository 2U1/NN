{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import functools\n",
    "from tqdm.notebook import tqdm\n",
    "import subprocess\n",
    "import glob\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    \n",
    "\n",
    "    path_list = []\n",
    "    \n",
    "    for c in tqdm(alphabet):\n",
    "        target_path = os.path.join(rootpath + c + '/*.abc')\n",
    "        for path in glob.glob(target_path):\n",
    "            path_list.append(path)\n",
    "\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_song_data(text):\n",
    "    # extract song from abc notation\n",
    "    # remove header\n",
    "    text = re.sub(r'%%.*', '', text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\n{2,}',r'\\n',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_song_to_abc(song, filename):\n",
    "    save_name = \"/result/{}.abc\".format(filename)\n",
    "    with open(save_name, 'w') as f:\n",
    "        f.write(song)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def abc2wav(abc_file):\n",
    "    suf = abc_file.rsrip('.abc')\n",
    "    cmd = \"abc2midi {} -o {}\".format(abc_file, suf + \".mid\")\n",
    "    os.system(cmd)\n",
    "    cmd = \"timidity {}.mid -Ow {}.wav\".format(suf, suf)\n",
    "\n",
    "    return os.system()\n",
    "\n",
    "def play_wav(wav_file):\n",
    "    return ipythondisplay.Audio(wav_file)\n",
    "\n",
    "def play_song(song):\n",
    "    basename = save_song_to_abc(song)\n",
    "    ret = abc2wav(basename + \".abc\")\n",
    "    if ret == 0:\n",
    "        return play_wav(basename + \".wav\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e1dc791394b9bb629bf7cc4329a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "rootpath = cwd + '/notation/'\n",
    "notation_list = make_datapath_list(rootpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af0eb748a3c42268d084b43672322e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songs = []\n",
    "\n",
    "for notation in tqdm(notation_list):\n",
    "    with open(notation, 'r') as f:\n",
    "        text = f.read()\n",
    "        song = extract_song_data(text)\n",
    "        songs.append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example song: \n",
      "X: 0\n",
      "T: Austria\n",
      "Z: Franz Joseph Hayden, 1797\n",
      "Z: Public  domain\n",
      "L: 1/4\n",
      "M: 4/4\n",
      "V: P1 name=\"Unnamed-000\"\n",
      "V: P2 name=\"Unnamed-001\"\n",
      "V: P3 name=\"Tempo Track\"\n",
      "K: Eb\n",
      "[V: P1]  [B,3/E3/] [B,/F/] [EG] [DF] | [FA] [EG] [D/F/]D/ [B,E] | [C/c/]D/ [EB] [FA] [EG] | [CF] [E/G/]E/ [D2B2] | [B,3/E3/] [B,/F/] [EG] [DF] | [FA] [EG] [D/F/]D/ [B,E] | [C/c/]D/ [EB] [FA] [EG] | [CF] [E/G/]E/ [D2B2] | [B,F] [B,G] [B,/F/]D/ B, | [C/A/]D/ [EG] [D/F/][B,/D/] B, | [B,B] [C/A/]D/ [E3/G3/] [E/G/] | [E3/=A3/] [E/A/] [D2B2] | [E3/e3/] [E/d/] [E/d/]c/ [EB] | [E3/c3/] [E/B/] [D/B/]A/ [EG] | [DF] [D/G/]A/ [E/B/]c/ [C/A/]F/ | [B,E] [D/G/]F/ E2- | E2z2|]\n",
      "[V: P2]  [E,3/G,3/] [E,/A,/] [E,B,] [B,,B,] | [D,B,] [E,B,] [B,,A,] [E,G,] | A, [G,B,] [D,B,] [E,B,] | [A,,A,] [=A,,C] [B,,2F,2] | [E,3/G,3/] [E,/A,/] [E,B,] [B,,B,] | [D,B,] [E,B,] [B,,A,] [E,G,] | A, [G,B,] [D,B,] [E,B,] | [A,,A,] [=A,,C] [B,,2F,2] | [B,,D,] [B,,E,] [B,,/D,/]F,/ [B,,/A,/]G,/ | [B,,F,] [B,,/E,/]G,/ [B,,/B,/]F,/ [B,,/D,/]A,,/ | [G,,G,] [A,,/F,/]B,,/ [C,3/E,3/] [C,/C/] | [F,3/C3/] [F,,/F,/] [B,,2F,2] | [G,3/C3/] [G,/B,/] A, [E,G,] | A,3/ [G,/B,/] [F,B,] [E,B,] | [B,,B,] [A,,B,] [G,,/B,/]E,/ [A,,/C/]A,/ | [B,,G,] [B,,A,] [E,,2-E,2-G,2-] | [E,,2E,2G,2]z2|]\n",
      "[V: P3]  z4|]\n"
     ]
    }
   ],
   "source": [
    "example_song = songs[119]\n",
    "print(\"Example song: \")\n",
    "print(example_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 109 unique characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "joined = \"\\n\\n\".join(songs)\n",
    "vocab = sorted(set(joined))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_string(string):\n",
    "    vectorized_list = np.array([char2idx[s] for s in string])\n",
    "    return vectorized_list\n",
    "\n",
    "vectorized_songs = vectorize_string(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(vecotorized_songs, seq_length, batch_size):\n",
    "    n = vecotorized_songs.shape[0] - 1\n",
    "    idx = np.random.choice(n - seq_length, batch_size)\n",
    "\n",
    "    input_batch = [vecotorized_songs[i:i+seq_length] for i in idx]\n",
    "    target_batch = [vecotorized_songs[i+1:i+seq_length+1] for i in idx]\n",
    "\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(target_batch, [batch_size, seq_length])\n",
    "\n",
    "    return torch.Tensor(x_batch), torch.Tensor(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model for generating music\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, seq_length, dropout_p=0.5):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, self.n_layers, dropout=self.dropout_p)\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = x.view(batch_size * self.seq_length, self.hidden_dim)\n",
    "        x = self.fc(x)\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe294e6606534daba89c1dc14d4f5ef002211ec8430f3955bebe6e14ba2710b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
